{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distribution_fit_class import DistributionFit\n",
    "from portfolio_optimization_class import PortfolioOptimization, optimize_windows\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = pd.read_csv(r'data\\random_data\\1_stocks_per_sector.csv', index_col=0, parse_dates=True)\n",
    "file_path = r'data\\random_data\\1_stocks_per_sector.csv'\n",
    "\n",
    "copulas = [\"clayton_random\", \"gaussian\", \"t_student\"]\n",
    "distributions = [\"gauss_dist\", \"t_dist\"]\n",
    "window_size = 32\n",
    "taus = [0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.15, 0.2]\n",
    "maximum_weight = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing window: 0, tau: 0.0005\n",
      "Processing window: 5, tau: 0.0005\n",
      "Processing window: 10, tau: 0.0005\n",
      "Processing window: 15, tau: 0.0005\n",
      "Processing window: 20, tau: 0.0005\n",
      "Processing window: 25, tau: 0.0005\n",
      "Processing window: 30, tau: 0.0005\n",
      "Processing window: 35, tau: 0.0005\n",
      "Processing window: 40, tau: 0.0005\n",
      "Processing window: 45, tau: 0.0005\n",
      "Processing window: 50, tau: 0.0005\n",
      "Processing window: 55, tau: 0.0005\n",
      "Processing window: 60, tau: 0.0005\n",
      "Processing window: 0, tau: 0.001\n",
      "Processing window: 5, tau: 0.001\n",
      "Processing window: 10, tau: 0.001\n",
      "Processing window: 15, tau: 0.001\n",
      "Processing window: 20, tau: 0.001\n",
      "Processing window: 25, tau: 0.001\n",
      "Processing window: 30, tau: 0.001\n",
      "Processing window: 35, tau: 0.001\n",
      "Processing window: 40, tau: 0.001\n",
      "Processing window: 45, tau: 0.001\n",
      "Processing window: 50, tau: 0.001\n",
      "Processing window: 55, tau: 0.001\n",
      "Processing window: 60, tau: 0.001\n",
      "Processing window: 0, tau: 0.002\n",
      "Processing window: 5, tau: 0.002\n",
      "Processing window: 10, tau: 0.002\n",
      "Processing window: 15, tau: 0.002\n",
      "Processing window: 20, tau: 0.002\n",
      "Processing window: 25, tau: 0.002\n",
      "Processing window: 30, tau: 0.002\n",
      "Processing window: 35, tau: 0.002\n",
      "Processing window: 40, tau: 0.002\n",
      "Processing window: 45, tau: 0.002\n",
      "Processing window: 50, tau: 0.002\n",
      "Processing window: 55, tau: 0.002\n",
      "Processing window: 60, tau: 0.002\n",
      "Processing window: 0, tau: 0.005\n",
      "Processing window: 5, tau: 0.005\n",
      "Processing window: 10, tau: 0.005\n",
      "Processing window: 15, tau: 0.005\n",
      "Processing window: 20, tau: 0.005\n",
      "Processing window: 25, tau: 0.005\n",
      "Processing window: 30, tau: 0.005\n",
      "Processing window: 35, tau: 0.005\n",
      "Processing window: 40, tau: 0.005\n",
      "Processing window: 45, tau: 0.005\n",
      "Processing window: 50, tau: 0.005\n",
      "Processing window: 55, tau: 0.005\n",
      "Processing window: 60, tau: 0.005\n",
      "Processing window: 0, tau: 0.01\n",
      "Processing window: 5, tau: 0.01\n",
      "Processing window: 10, tau: 0.01\n",
      "Processing window: 15, tau: 0.01\n",
      "Processing window: 20, tau: 0.01\n",
      "Processing window: 25, tau: 0.01\n",
      "Processing window: 30, tau: 0.01\n",
      "Processing window: 35, tau: 0.01\n",
      "Processing window: 40, tau: 0.01\n",
      "Processing window: 45, tau: 0.01\n",
      "Processing window: 50, tau: 0.01\n",
      "Processing window: 55, tau: 0.01\n",
      "Processing window: 60, tau: 0.01\n",
      "Processing window: 0, tau: 0.02\n",
      "Processing window: 5, tau: 0.02\n",
      "Processing window: 10, tau: 0.02\n",
      "Processing window: 15, tau: 0.02\n",
      "Processing window: 20, tau: 0.02\n",
      "Processing window: 25, tau: 0.02\n",
      "Processing window: 30, tau: 0.02\n",
      "Processing window: 35, tau: 0.02\n",
      "Processing window: 40, tau: 0.02\n",
      "Processing window: 45, tau: 0.02\n",
      "Processing window: 50, tau: 0.02\n",
      "Processing window: 55, tau: 0.02\n",
      "Processing window: 60, tau: 0.02\n",
      "Processing window: 0, tau: 0.05\n",
      "Processing window: 5, tau: 0.05\n",
      "Processing window: 10, tau: 0.05\n",
      "Processing window: 15, tau: 0.05\n",
      "Processing window: 20, tau: 0.05\n",
      "Processing window: 25, tau: 0.05\n",
      "Processing window: 30, tau: 0.05\n",
      "Processing window: 35, tau: 0.05\n",
      "Processing window: 40, tau: 0.05\n",
      "Processing window: 45, tau: 0.05\n",
      "Processing window: 50, tau: 0.05\n",
      "Processing window: 55, tau: 0.05\n",
      "Processing window: 60, tau: 0.05\n",
      "Processing window: 0, tau: 0.1\n",
      "Processing window: 5, tau: 0.1\n",
      "Processing window: 10, tau: 0.1\n",
      "Processing window: 15, tau: 0.1\n",
      "Processing window: 20, tau: 0.1\n",
      "Processing window: 25, tau: 0.1\n",
      "Processing window: 30, tau: 0.1\n",
      "Processing window: 35, tau: 0.1\n",
      "Processing window: 40, tau: 0.1\n",
      "Processing window: 45, tau: 0.1\n",
      "Processing window: 50, tau: 0.1\n",
      "Processing window: 55, tau: 0.1\n",
      "Processing window: 60, tau: 0.1\n",
      "Processing window: 0, tau: 0.15\n",
      "Processing window: 5, tau: 0.15\n",
      "Processing window: 10, tau: 0.15\n",
      "Processing window: 15, tau: 0.15\n",
      "Processing window: 20, tau: 0.15\n",
      "Processing window: 25, tau: 0.15\n",
      "Processing window: 30, tau: 0.15\n",
      "Processing window: 35, tau: 0.15\n",
      "Processing window: 40, tau: 0.15\n",
      "Processing window: 45, tau: 0.15\n",
      "Processing window: 50, tau: 0.15\n",
      "Processing window: 55, tau: 0.15\n",
      "Processing window: 60, tau: 0.15\n",
      "Processing window: 0, tau: 0.2\n",
      "Processing window: 5, tau: 0.2\n",
      "Processing window: 10, tau: 0.2\n",
      "Processing window: 15, tau: 0.2\n",
      "Processing window: 20, tau: 0.2\n",
      "Processing window: 25, tau: 0.2\n",
      "Processing window: 30, tau: 0.2\n",
      "Processing window: 35, tau: 0.2\n",
      "Processing window: 40, tau: 0.2\n",
      "Processing window: 45, tau: 0.2\n",
      "Processing window: 50, tau: 0.2\n",
      "Processing window: 55, tau: 0.2\n",
      "Processing window: 60, tau: 0.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tau_aggregation = []\n",
    "for tau in taus:\n",
    "    tau_dict = {}\n",
    "    portfolios = optimize_windows(number_of_quarters=window_size, tau=tau, maximum_weight=maximum_weight, data_path=file_path)\n",
    "\n",
    "    expected_validation_values_norm = []\n",
    "    expected_scoring_values_norm = []\n",
    "    expected_validation_values_t = []\n",
    "    expected_scoring_values_t = []\n",
    "    for window in range(0, 63):  # 60 windows as specified\n",
    "        if window % 5 == 0:\n",
    "            print(f'Processing window: {window}, tau: {tau}')\n",
    "\n",
    "        # Select returns window for fitting distributions\n",
    "        returns_window = returns_df.iloc[window: 32 + window_size]\n",
    "        distribution_fit = DistributionFit()\n",
    "        distribution_fit.set_df(returns_window)\n",
    "        distribution_fit.fit_multivariate_distributions(4)  # Fit the multivariate distributions\n",
    "\n",
    "        # Generate samples from fitted distributions\n",
    "        distribution_fit.generate_multivariate_normal_samples(10000)\n",
    "        distribution_fit.generate_multivariate_t_samples(10000)\n",
    "\n",
    "        samples_normal = distribution_fit.get_generated_multivariated_normal_samples()\n",
    "        samples_t = distribution_fit.get_generated_multivariated_t_samples()\n",
    "        # print(samples_normal)\n",
    "\n",
    "        distributions_samples = [\n",
    "            (samples_normal, \"gauss_dist\"),\n",
    "            (samples_t, \"t_dist\")\n",
    "        ]\n",
    "\n",
    "        for simulated_returns, dist_name in distributions_samples:\n",
    "            weights = portfolios.iloc[window].filter(regex=\"^w\\d+$\").values\n",
    "            expectile = -portfolios.iloc[window][\"EVAR\"]\n",
    "            weighted_returns = simulated_returns.values * weights\n",
    "\n",
    "            portfolio_returns = np.sum(weighted_returns, axis=1)\n",
    "            # print(len(portfolio_returns))\n",
    "            validation_values = (1 - tau) * np.minimum(portfolio_returns - expectile, 0) - tau * np.maximum(portfolio_returns - expectile, 0)\n",
    "            scoring_values = (1 - tau) * np.minimum((portfolio_returns - expectile)**2, 0) + tau * np.maximum((portfolio_returns - expectile)**2, 0)\n",
    "\n",
    "            expected_validation_value = np.mean(validation_values)\n",
    "            expected_scoring_value = np.mean(scoring_values)\n",
    "\n",
    "            if dist_name == \"gauss_dist\":\n",
    "                expected_validation_values_norm.append(expected_validation_value)\n",
    "                expected_scoring_values_norm.append(expected_scoring_value)\n",
    "            elif dist_name == \"t_dist\":\n",
    "                expected_validation_values_t.append(expected_validation_value)\n",
    "                expected_scoring_values_t.append(expected_scoring_value)\n",
    "\n",
    "    tau_dict[f'gauss_dist+val'] = expected_validation_values_norm\n",
    "    tau_dict[f'gauss_dist+score'] = expected_scoring_values_norm\n",
    "    tau_dict[f't_dist+val'] = expected_validation_values_t\n",
    "    tau_dict[f't_dist+scor'] = expected_scoring_values_t\n",
    "    tau_str = str(tau).replace(\".\", \"_\")\n",
    "    output_path = r\"multivariate_scores/\" + f'multivariate_dists_scores_11_stocks__{tau_str}.csv'\n",
    "    tau_df = pd.DataFrame.from_dict(tau_dict)\n",
    "    tau_df.to_csv(output_path)\n",
    "    tau_aggregation.append(tau_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauss_dist+val</th>\n",
       "      <th>gauss_dist+score</th>\n",
       "      <th>t_dist+val</th>\n",
       "      <th>t_dist+scor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.008157</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.014506</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003755</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004199</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.010409</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.004210</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.009954</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003616</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.009969</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.001809</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.000080</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gauss_dist+val  gauss_dist+score  t_dist+val  t_dist+scor\n",
       "0        -0.008157          0.000005   -0.014506     0.000007\n",
       "1        -0.003755          0.000006   -0.009763     0.000009\n",
       "2        -0.004199          0.000007   -0.010409     0.000009\n",
       "3        -0.004210          0.000006   -0.009954     0.000009\n",
       "4        -0.003616          0.000007   -0.009969     0.000010\n",
       "..             ...               ...         ...          ...\n",
       "58       -0.000093          0.000007   -0.001356     0.000008\n",
       "59       -0.000176          0.000007   -0.001809     0.000008\n",
       "60       -0.000080          0.000008   -0.001201     0.000009\n",
       "61       -0.000061          0.000006   -0.001087     0.000007\n",
       "62       -0.000044          0.000004   -0.000053     0.000004\n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_aggregation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_dfs = []\n",
    "for tau_idx, tau in enumerate(taus):\n",
    "    df = tau_aggregation[tau_idx]\n",
    "    stats = pd.DataFrame()\n",
    "    means = []\n",
    "    stds = []\n",
    "    percentiles_5 = []\n",
    "    percentiles_95 = []\n",
    "    for col in df.columns:\n",
    "        means.append(df[col].mean())\n",
    "        stds.append(df[col].std())\n",
    "        percentiles_5.append(np.percentile(df[col], 5))\n",
    "        percentiles_95.append(np.percentile(df[col], 95))\n",
    "    stats[f\"Models\"] = df.columns.to_list()\n",
    "    stats[\"MEAN\"] = means\n",
    "    stats[f\"STD\"] = stds\n",
    "    stats[f\"5th PERCENTIL\"] = percentiles_5\n",
    "    stats[f\"95th PERCENTIL\"] = percentiles_95\n",
    "    stats.sort_values(by=\"MEAN\", inplace=True)\n",
    "    stat_dfs.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>STD</th>\n",
       "      <th>5th PERCENTIL</th>\n",
       "      <th>95th PERCENTIL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_dist+val</td>\n",
       "      <td>-0.009212</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>-0.003067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gauss_dist+val</td>\n",
       "      <td>-0.004702</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>-0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gauss_dist+score</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_dist+scor</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Models      MEAN       STD  5th PERCENTIL  95th PERCENTIL\n",
       "2        t_dist+val -0.009212  0.003438      -0.014390       -0.003067\n",
       "0    gauss_dist+val -0.004702  0.001842      -0.007688       -0.001882\n",
       "1  gauss_dist+score  0.000206  0.000037       0.000154        0.000275\n",
       "3       t_dist+scor  0.000282  0.000059       0.000199        0.000378"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_dfs[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
