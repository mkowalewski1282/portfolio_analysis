{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distribution_fit_class import DistributionFit\n",
    "from portfolio_optimization_class import PortfolioOptimization, optimize_windows\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MMM', 'A', 'SNPS', 'OMC', 'ROST', 'EIX', 'GS', 'NUE', 'PSA', 'GIS',\n",
       "       'WMB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_fit = DistributionFit()\n",
    "\n",
    "file_path = r'data\\random_data\\1_stocks_per_sector_1_iter.csv'\n",
    "distribution_fit.load_df_from_csv(file_path)\n",
    "\n",
    "returns_df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "returns_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 32\n",
    "taus = [0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.15, 0.2]\n",
    "maximum_weight = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_aggregation = []\n",
    "for tau_index, tau in enumerate(taus):\n",
    "    tau_dict = {}\n",
    "    portfolios = optimize_windows(number_of_quarters=window_size, tau=tau, maximum_weight=maximum_weight, data_path=file_path)\n",
    "\n",
    "    expected_validation_values_norm = []\n",
    "    expected_scoring_values_norm = []\n",
    "    expected_validation_values_t = []\n",
    "    expected_scoring_values_t = []\n",
    "    for window in range(0, 64):\n",
    "        if window % 5 == 0:\n",
    "            print(f'Tau: {tau}, window - {window}')\n",
    "        returns_window = returns_df.iloc[window : window + window_size]\n",
    "        distribution_fit = DistributionFit()\n",
    "        distribution_fit.set_df(returns_window)\n",
    "        distribution_fit.fit_distribution_all_stocks()\n",
    "\n",
    "        simulated_data_path = r'data\\copulas_outputs\\clayton_random_fixed_coefficient.csv'\n",
    "\n",
    "        df = pd.read_csv(simulated_data_path)\n",
    "        df.columns = returns_df.columns          # RENAME OF COLUMNS CAUSE THEY GOT MIXED UP IN ANALYSIS IN R !!!!!!!!!!!!!!!!\n",
    "        # df.to_csv(simulated_data_path, index=False)\n",
    "\n",
    "        distribution_fit.set_simulated_data_from_df(df.iloc[:number_of_samples])\n",
    "\n",
    "        distribution_fit.calculate_returns_from_simulated_quantiles()\n",
    "        returns_norm = distribution_fit.get_simulated_return_norm()\n",
    "        returns_t = distribution_fit.get_simulated_return_t_student()\n",
    "        weights = portfolios.iloc[window].filter(regex=\"^w\\d+$\").values\n",
    "\n",
    "        expectile = -portfolios.iloc[window][\"EVAR\"]\n",
    "\n",
    "        portfolio_returns_norm = np.sum(returns_norm.values * weights, axis=1)\n",
    "        validation_values_norm = (1 - tau) * np.minimum(portfolio_returns_norm - expectile, 0) - tau * np.maximum(portfolio_returns_norm - expectile, 0)\n",
    "        scoring_values_norm = (1 - tau) * np.minimum((portfolio_returns_norm - expectile)**2, 0) + tau * np.maximum((portfolio_returns_norm - expectile)**2, 0)\n",
    "        expected_validation_values_norm.append(np.mean(validation_values_norm))\n",
    "        expected_scoring_values_norm.append(np.mean(scoring_values_norm))\n",
    "\n",
    "        portfolio_returns_t = np.sum(returns_t.values * weights, axis=1)\n",
    "        validation_values_t = (1 - tau) * np.minimum(portfolio_returns_t - expectile, 0) - tau * np.maximum(portfolio_returns_t - expectile, 0)\n",
    "        scoring_values_t = (1 - tau) * np.minimum((portfolio_returns_t - expectile)**2, 0) + tau * np.maximum((portfolio_returns_t - expectile)**2, 0)\n",
    "        expected_validation_values_t.append(np.mean(validation_values_t))\n",
    "        expected_scoring_values_t.append(np.mean(scoring_values_t))\n",
    "\n",
    "    tau_dict[f'{copula}+gauss_dist+val'] = expected_validation_values_norm\n",
    "    tau_dict[f'{copula}+gauss_dist+score'] = expected_scoring_values_norm\n",
    "    tau_dict[f'{copula}+t_dist+val'] = expected_validation_values_t\n",
    "    tau_dict[f'{copula}+t_dist+scor'] = expected_scoring_values_t\n",
    "\n",
    "tau_aggregation.append(tau_dict)\n",
    "df = pd.DataFrame.from_dict(tau_dict)\n",
    "tau_str = str(tau).replace(\".\", \"_\")\n",
    "# output_path = r\"../scores/taus/\" + f'tau_{tau_str}/scores_{tau_str}{batch_num}.csv'\n",
    "output_path = r\"../scores/taus/\" + f'tau_{tau_str}/scores_11_stocks_{tau_str}_iter_{iter}.csv'\n",
    "df.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
